# ğŸ”¬ SystÃ¨me Hybride XAI

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![SysCRED](https://img.shields.io/badge/Integrated_in-SysCRED-blue)](https://github.com/DominiqueLoyer/systemFactChecking)
**Backend Flask pour systÃ¨me hybride de vÃ©rification de crÃ©dibilitÃ© avec Explainable AI (XAI)**

PhD Research - Dominique S. Loyer | UQAM

---

## ğŸ“‹ Overview

SystÃ¨me hybride combinant approches symboliques et neuronales pour la vÃ©rification de crÃ©dibilitÃ© informationnelle avec capacitÃ©s d'explicabilitÃ© (XAI):

- **Backend Flask**: API REST pour l'Ã©valuation de crÃ©dibilitÃ©
- **Interface Web**: Frontend HTML/CSS/JS interactif
- **Documentation XAI**: StratÃ©gie d'explicabilitÃ© des dÃ©cisions
- **Neuro-symbolique**: Fusion rÃ¨gles OWL + modÃ¨les Transformers

---

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/DominiqueLoyer/systeme-hybride-xai.git
cd systeme-hybride-xai

# Installer les dÃ©pendances
pip install flask

# Lancer le serveur
python backend_flask.py
```

### AccÃ¨s

Le serveur dÃ©marre sur `http://localhost:5000`

---

## ğŸ“ Project Structure

```
systeme-hybride-xai/
â”œâ”€â”€ README.md                           # Ce fichier
â”œâ”€â”€ backend_flask.py                    # â­ Serveur Flask principal
â”œâ”€â”€ Copie de Backend Flask_app.py       # Version alternative
â”œâ”€â”€ backend_7juin25.html                # Interface web
â”œâ”€â”€ interface806.html                   # Interface alternative
â””â”€â”€ Analyse et StratÃ©gie XAI...         # Documentation XAI
```

---

## ğŸ“¡ API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/verify` | POST | VÃ©rification de crÃ©dibilitÃ© |
| `/api/health` | GET | Ã‰tat du serveur |
| `/api/explain` | POST | ExplicabilitÃ© XAI |

### Exemple Request

```bash
curl -X POST http://localhost:5000/api/verify \
  -H "Content-Type: application/json" \
  -d '{"input_data": "https://www.exemple.com/article"}'
```

### Exemple Response

```json
{
  "scoreCredibilite": 0.75,
  "niveauCredibilite": "HIGH",
  "explanation": {
    "factors": ["source_reputation", "content_analysis"],
    "weights": [0.4, 0.6]
  }
}
```

---

## ğŸ”§ Architecture XAI

Le systÃ¨me utilise une approche hybride pour l'explicabilitÃ©:

1. **RÃ¨gles symboliques**: Ontologie OWL pour les rÃ¨gles de base
2. **Attention Weights**: Visualisation des poids d'attention Transformer
3. **LIME/SHAP**: ExplicabilitÃ© locale des prÃ©dictions

---

## ğŸ·ï¸ Citation

```bibtex
@software{loyer2025hybride,
  author = {Loyer, Dominique S.},
  title = {SystÃ¨me Hybride XAI: Neuro-Symbolic Credibility Verification},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/DominiqueLoyer/systeme-hybride-xai}
}
```

---

## ğŸ“œ License

MIT License
